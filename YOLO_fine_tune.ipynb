{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer Vision: YOLO for identifying Formula 1 Teams\n",
    "\n",
    "This notebook contains the essential code for training a YOLOv8 model to detect and classify Formula 1 teams from images and videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "from torch.optim import Adam\n",
    "import numpy as np\n",
    "import random\n",
    "import shutil\n",
    "import yaml\n",
    "from collections import Counter\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Path Configuration\n",
    "\n",
    "Define the paths to your training images and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path constants - update these to match your file structure\n",
    "TRAIN_IMAGE = r\"f1-dataset/train/images/1-2023-Brazilian-GP-FP1-20_jpg.rf.2f3d25867c8e1661f6070ae5a84c6dd4.jpg\"\n",
    "IMAGE_FOLDER = r\"f1-dataset/train/images\"\n",
    "DATA_YAML = r\"f1-dataset/data.yaml\"\n",
    "PROJECT_DIR = r\"yolo-files/runs\"\n",
    "WEIGHTS_DIR = r\"weights\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check PyTorch Version and GPU Availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check PyTorch version and CUDA availability\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"CUDA is not available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Configuration\n",
    "\n",
    "Define the parameters for training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device and training configuration\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "NUM_CLASSES = 10  # Number of F1 teams\n",
    "LEARNING_RATE = 0.0005\n",
    "BATCH_SIZE = 8  # Adjust based on GPU memory\n",
    "FINE_TUNED_BATCH_SIZE = 6\n",
    "NUM_WORKERS = 8  # Increase if you have more CPU cores\n",
    "NUM_EPOCHS = 50  # Or more, depending on performance\n",
    "FINE_TUNED_EPOCHS = 30\n",
    "AUGMENTATION = True  # Data augmentation flag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Verification\n",
    "\n",
    "Verify that the training images can be loaded correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify a sample image loads correctly\n",
    "train_image = cv2.imread(TRAIN_IMAGE)\n",
    "if train_image is None:\n",
    "    print(\"Error loading the image\")\n",
    "else:\n",
    "    print(\"Image loaded correctly: \", train_image.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Image Sizes\n",
    "\n",
    "Ensure all images have consistent dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the image folder\n",
    "image_folder = IMAGE_FOLDER\n",
    "# List to store image sizes\n",
    "sizes = set()\n",
    "\n",
    "# Check the size of each image\n",
    "for image_name in os.listdir(image_folder):\n",
    "    image_path = os.path.join(image_folder, image_name)\n",
    "    img = cv2.imread(image_path)\n",
    "\n",
    "    if img is not None:\n",
    "        img_size = img.shape  # (height, width, channels)\n",
    "        sizes.add(img_size)\n",
    "    else:\n",
    "        print(f\"Error loading image: {image_name}\")\n",
    "        \n",
    "# Check if all images have the same size\n",
    "if len(sizes) == 1:\n",
    "    print(\"All images have the same size.\")\n",
    "else:\n",
    "    print(\"There are images with different sizes. The sizes found are:\")\n",
    "    for size in sizes:\n",
    "        print(size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions\n",
    "\n",
    "Functions for model setup, training, evaluation and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For reproducibility\n",
    "def set_seed(seed=42):\n",
    "    \"\"\"Set random seeds for reproducibility\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    print(f\"Random seed set to {seed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a YOLO model\n",
    "def load_model(weights_path=None):\n",
    "    \"\"\"Load a YOLO model from weights or use pretrained\"\"\"\n",
    "    if weights_path and os.path.exists(weights_path):\n",
    "        model = YOLO(weights_path)\n",
    "        print(f\"Loaded model from {weights_path}\")\n",
    "    else:\n",
    "        model = YOLO(\"yolov8m.pt\")  # Load pretrained model\n",
    "        print(\"Loaded pretrained YOLOv8m model\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update data.yaml with class weights\n",
    "def update_data_yaml(yaml_path, class_weights=None):\n",
    "    \"\"\"Update data.yaml with custom class weights\"\"\"\n",
    "    # Read existing data.yaml\n",
    "    with open(yaml_path, 'r') as f:\n",
    "        data_config = yaml.safe_load(f)\n",
    "    \n",
    "    # Create backup if none exists\n",
    "    backup_file = yaml_path + '.backup'\n",
    "    if not os.path.exists(backup_file):\n",
    "        shutil.copy(yaml_path, backup_file)\n",
    "        print(f\"Backup created at {backup_file}\")\n",
    "    \n",
    "    # Get class names\n",
    "    class_names = data_config.get('names', [])\n",
    "    \n",
    "    # Update with class weights if provided\n",
    "    if class_weights:\n",
    "        data_config['class_weights'] = class_weights\n",
    "        \n",
    "        # Save the updated file\n",
    "        with open(yaml_path, 'w') as f:\n",
    "            yaml.dump(data_config, f, default_flow_style=False)\n",
    "        \n",
    "        print(f\"Updated {yaml_path} with custom class weights:\")\n",
    "        for i, name in enumerate(class_names):\n",
    "            weight = class_weights.get(i, 1.0)\n",
    "            print(f\"  - {name}: {weight}\")\n",
    "    \n",
    "    return data_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training Function\n",
    "\n",
    "Core function to train the YOLO model with optimized hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a model with given parameters\n",
    "def train_model(model, data_yaml_path, epochs=NUM_EPOCHS, batch_size=BATCH_SIZE, \n",
    "                lr=LEARNING_RATE, project_path=PROJECT_DIR, run_name='train'):\n",
    "    \"\"\"Train a YOLO model with specified parameters\"\"\"\n",
    "    \n",
    "    print(f\"\\n=== TRAINING CONFIGURATION ===\")\n",
    "    print(f\"Epochs: {epochs}\")\n",
    "    print(f\"Batch size: {batch_size}\")\n",
    "    print(f\"Learning rate: {lr}\")\n",
    "    print(f\"Project path: {project_path}\")\n",
    "    print(f\"Run name: {run_name}\")\n",
    "    print(\"===================================\\n\")\n",
    "    \n",
    "    # Check if directories exist, create if not\n",
    "    os.makedirs(project_path, exist_ok=True)\n",
    "    \n",
    "    results = model.train(\n",
    "        data=data_yaml_path,\n",
    "        epochs=epochs,\n",
    "        batch=batch_size,\n",
    "        imgsz=640,  # Image size\n",
    "        optimizer=\"AdamW\",\n",
    "        lr0=lr,\n",
    "        lrf=0.01,  # Final LR factor\n",
    "        cos_lr=True,  # Use cosine learning rate schedule\n",
    "        momentum=0.937,\n",
    "        weight_decay=0.0005,\n",
    "        warmup_epochs=3,\n",
    "        \n",
    "        # Loss weightings\n",
    "        box=7.5,  # Box loss weight\n",
    "        cls=7.0,  # Class loss weight\n",
    "        dfl=1.5,  # Distribution focal loss weight\n",
    "        \n",
    "        # Data augmentation \n",
    "        mosaic=0.8,        # Mosaic augmentation\n",
    "        mixup=0.2,         # Mixup augmentation\n",
    "        copy_paste=0.1,    # Copy-paste augmentation\n",
    "        degrees=15.0,      # Rotation augmentation\n",
    "        translate=0.2,     # Translation augmentation\n",
    "        scale=0.5,         # Scale augmentation\n",
    "        shear=1.0,         # Shear augmentation\n",
    "        fliplr=0.5,        # Horizontal flip probability\n",
    "        flipud=0.05,       # Vertical flip probability\n",
    "        hsv_h=0.015,       # Hue augmentation\n",
    "        hsv_s=0.7,         # Saturation augmentation\n",
    "        hsv_v=0.5,         # Value/brightness augmentation\n",
    "        \n",
    "        # Early stopping\n",
    "        patience=15,\n",
    "        \n",
    "        # Device\n",
    "        device=DEVICE,\n",
    "        \n",
    "        # Pretrained weights\n",
    "        pretrained=True,\n",
    "        \n",
    "        # Save settings\n",
    "        project=project_path,\n",
    "        name=run_name,\n",
    "        save_period=5,      # Save checkpoint every 5 epochs\n",
    "        \n",
    "        # Additional options\n",
    "        verbose=True,       # Print training statistics\n",
    "        val=True,           # Run validation during training\n",
    "        plots=True,         # Create training plots\n",
    "    )\n",
    "    \n",
    "    print(f\"Training completed for {epochs} epochs\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-Tuning Function\n",
    "\n",
    "For fine-tuning an already trained model for better performance on specific classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tune a model\n",
    "def fine_tune_model(model, data_yaml_path, epochs=FINE_TUNED_EPOCHS, batch_size=FINE_TUNED_BATCH_SIZE,\n",
    "                    lr=LEARNING_RATE/3, project_path=PROJECT_DIR, run_name='fine_tune'):\n",
    "    \"\"\"Fine-tune a YOLO model with lower learning rate\"\"\"\n",
    "    \n",
    "    print(f\"\\n=== FINE-TUNING CONFIGURATION ===\")\n",
    "    print(f\"Epochs: {epochs}\")\n",
    "    print(f\"Batch size: {batch_size}\")\n",
    "    print(f\"Learning rate: {lr} (reduced for fine-tuning)\")\n",
    "    print(f\"Project path: {project_path}\")\n",
    "    print(f\"Run name: {run_name}\")\n",
    "    print(\"===================================\\n\")\n",
    "    \n",
    "    results = model.train(\n",
    "        data=data_yaml_path,\n",
    "        epochs=epochs,\n",
    "        batch=batch_size,\n",
    "        imgsz=800,            # Larger image size for fine details\n",
    "        optimizer=\"AdamW\",\n",
    "        lr0=lr,               # Lower learning rate for fine-tuning\n",
    "        lrf=0.000001,         # Very low final learning rate\n",
    "        cos_lr=True,\n",
    "        momentum=0.937,\n",
    "        weight_decay=0.001,   # Increased regularization\n",
    "        warmup_epochs=3,\n",
    "        \n",
    "        # Loss weightings - adjusted for fine-tuning\n",
    "        box=6.0,\n",
    "        cls=9.0,              # Higher class weight for better classification\n",
    "        dfl=1.5,\n",
    "        \n",
    "        # Less aggressive augmentation for fine-tuning\n",
    "        mosaic=0.7,\n",
    "        mixup=0.15,\n",
    "        copy_paste=0.1,\n",
    "        degrees=10.0,         # Less rotation\n",
    "        translate=0.1,\n",
    "        scale=0.4,\n",
    "        shear=0.5,            # Less shear\n",
    "        fliplr=0.5,\n",
    "        flipud=0.01,          # Minimal vertical flipping\n",
    "        hsv_h=0.01,           # Less color distortion\n",
    "        hsv_s=0.5,\n",
    "        hsv_v=0.3,\n",
    "        \n",
    "        # Early stopping - more patience\n",
    "        patience=20,\n",
    "        \n",
    "        # Device\n",
    "        device=DEVICE,\n",
    "        \n",
    "        # Pretrained weights (use the current model)\n",
    "        pretrained=True,\n",
    "        \n",
    "        # Save settings\n",
    "        project=project_path,\n",
    "        name=run_name,\n",
    "        save_period=2,        # Save more frequently\n",
    "        \n",
    "        # Additional options\n",
    "        verbose=True,\n",
    "        val=True,\n",
    "        plots=True,\n",
    "    )\n",
    "    \n",
    "    print(f\"Fine-tuning completed for {epochs} epochs\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation and Saving Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate a model\n",
    "def evaluate_model(model):\n",
    "    \"\"\"Evaluate a YOLO model and print metrics\"\"\"\n",
    "    print(\"\\nEvaluating model...\")\n",
    "    metrics = model.val()\n",
    "    \n",
    "    print(f\"\\nEvaluation results:\")\n",
    "    print(f\"mAP50: {metrics.box.map50:.4f}\")\n",
    "    print(f\"mAP50-95: {metrics.box.map:.4f}\")\n",
    "    print(f\"Precision: {metrics.box.precision:.4f}\")\n",
    "    print(f\"Recall: {metrics.box.recall:.4f}\")\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a model\n",
    "def save_model(model, path):\n",
    "    \"\"\"Save a YOLO model to specified path\"\"\"\n",
    "    # Ensure directory exists\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "    \n",
    "    model.save(path)\n",
    "    print(f\"Model saved to {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test a model on images\n",
    "def test_model(model, test_images_path, save_results=True):\n",
    "    \"\"\"Test a YOLO model on test images\"\"\"\n",
    "    print(f\"Testing model on images in {test_images_path}...\")\n",
    "    \n",
    "    results = model.predict(\n",
    "        source=test_images_path,\n",
    "        conf=0.25,           # Confidence threshold\n",
    "        iou=0.45,            # IoU threshold\n",
    "        max_det=20,          # Maximum detections per image\n",
    "        save=save_results    # Save results to disk\n",
    "    )\n",
    "    \n",
    "    print(f\"Testing completed\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example workflow: Class Weight Balancing\n",
    "\n",
    "Function to update class weights based on model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Update class weights based on validation results\n",
    "def balance_class_weights(data_yaml_path, class_performance):\n",
    "    \"\"\"Update class weights based on model performance\n",
    "    \n",
    "    Args:\n",
    "        data_yaml_path: Path to data.yaml file\n",
    "        class_performance: Dictionary with class names as keys and mAP values as values\n",
    "    \"\"\"\n",
    "    # Read existing data.yaml\n",
    "    with open(data_yaml_path, 'r') as f:\n",
    "        data_config = yaml.safe_load(f)\n",
    "    \n",
    "    # Get class names\n",
    "    class_names = data_config.get('names', [])\n",
    "    \n",
    "    # Create class weights - higher weight for lower performing classes\n",
    "    class_weights = {}\n",
    "    for i, name in enumerate(class_names):\n",
    "        # Default weight is 1.0\n",
    "        weight = 1.0\n",
    "        \n",
    "        # If we have performance data for this class\n",
    "        if name in class_performance:\n",
    "            map_value = class_performance[name]\n",
    "            \n",
    "            # Inverse relationship: lower mAP gets higher weight\n",
    "            if map_value < 0.5:\n",
    "                weight = 2.0  # Very poor performance, high weight\n",
    "            elif map_value < 0.7:\n",
    "                weight = 1.5  # Medium performance, medium weight\n",
    "            elif map_value < 0.9:\n",
    "                weight = 1.0  # Good performance, normal weight\n",
    "            else:\n",
    "                weight = 0.8  # Excellent performance, slightly lower weight\n",
    "        \n",
    "        class_weights[i] = weight\n",
    "    \n",
    "    # Update data.yaml with new weights\n",
    "    return update_data_yaml(data_yaml_path, class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Individual Steps\n",
    "\n",
    "If you prefer to run steps individually, here are examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Load and train a model\n",
    "# model = load_model()\n",
    "# train_results = train_model(model, DATA_YAML, epochs=10, run_name='quick_training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Evaluate a model\n",
    "# metrics = evaluate_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Fine-tune a model for specific classes\n",
    "# Custom class weights for problematic classes\n",
    "# class_weights = {0: 1.0, 1: 1.0, 2: 1.0, 3: 1.0, 4: 1.5, 5: 2.0, 6: 1.0, 7: 1.2, 8: 1.0, 9: 1.0}\n",
    "# update_data_yaml(DATA_YAML, class_weights)\n",
    "# fine_tune_results = fine_tune_model(model, DATA_YAML, epochs=15, run_name='class_specific_tuning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Test a saved model\n",
    "# test_model = load_model('weights/f1_detection_fine_tuned.pt')\n",
    "# test_results = test_model(test_model, 'f1-dataset/test/images')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
