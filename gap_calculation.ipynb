{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer Vision: Gap Calculation using YOLO net and OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "from collections import Counter\n",
    "import time as pytime\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "YOLO(\n",
       "  (model): DetectionModel(\n",
       "    (model): Sequential(\n",
       "      (0): Conv(\n",
       "        (conv): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (1): Conv(\n",
       "        (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (2): C3k2(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(192, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0): C3k(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv3): Conv(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (m): Sequential(\n",
       "              (0): Bottleneck(\n",
       "                (cv1): Conv(\n",
       "                  (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "                (cv2): Conv(\n",
       "                  (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "              )\n",
       "              (1): Bottleneck(\n",
       "                (cv1): Conv(\n",
       "                  (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "                (cv2): Conv(\n",
       "                  (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): Conv(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (4): C3k2(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0): C3k(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv3): Conv(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (m): Sequential(\n",
       "              (0): Bottleneck(\n",
       "                (cv1): Conv(\n",
       "                  (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "                (cv2): Conv(\n",
       "                  (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "              )\n",
       "              (1): Bottleneck(\n",
       "                (cv1): Conv(\n",
       "                  (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "                (cv2): Conv(\n",
       "                  (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): Conv(\n",
       "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (6): A2C2f(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0-1): 2 x Sequential(\n",
       "            (0): ABlock(\n",
       "              (attn): AAttn(\n",
       "                (qkv): Conv(\n",
       "                  (conv): Conv2d(256, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(768, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): Identity()\n",
       "                )\n",
       "                (proj): Conv(\n",
       "                  (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): Identity()\n",
       "                )\n",
       "                (pe): Conv(\n",
       "                  (conv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256, bias=False)\n",
       "                  (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): Identity()\n",
       "                )\n",
       "              )\n",
       "              (mlp): Sequential(\n",
       "                (0): Conv(\n",
       "                  (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "                (1): Conv(\n",
       "                  (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): Identity()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): ABlock(\n",
       "              (attn): AAttn(\n",
       "                (qkv): Conv(\n",
       "                  (conv): Conv2d(256, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(768, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): Identity()\n",
       "                )\n",
       "                (proj): Conv(\n",
       "                  (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): Identity()\n",
       "                )\n",
       "                (pe): Conv(\n",
       "                  (conv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256, bias=False)\n",
       "                  (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): Identity()\n",
       "                )\n",
       "              )\n",
       "              (mlp): Sequential(\n",
       "                (0): Conv(\n",
       "                  (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "                (1): Conv(\n",
       "                  (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): Identity()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): Conv(\n",
       "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (8): A2C2f(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0-1): 2 x Sequential(\n",
       "            (0): ABlock(\n",
       "              (attn): AAttn(\n",
       "                (qkv): Conv(\n",
       "                  (conv): Conv2d(256, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(768, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): Identity()\n",
       "                )\n",
       "                (proj): Conv(\n",
       "                  (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): Identity()\n",
       "                )\n",
       "                (pe): Conv(\n",
       "                  (conv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256, bias=False)\n",
       "                  (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): Identity()\n",
       "                )\n",
       "              )\n",
       "              (mlp): Sequential(\n",
       "                (0): Conv(\n",
       "                  (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "                (1): Conv(\n",
       "                  (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): Identity()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): ABlock(\n",
       "              (attn): AAttn(\n",
       "                (qkv): Conv(\n",
       "                  (conv): Conv2d(256, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(768, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): Identity()\n",
       "                )\n",
       "                (proj): Conv(\n",
       "                  (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): Identity()\n",
       "                )\n",
       "                (pe): Conv(\n",
       "                  (conv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256, bias=False)\n",
       "                  (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): Identity()\n",
       "                )\n",
       "              )\n",
       "              (mlp): Sequential(\n",
       "                (0): Conv(\n",
       "                  (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "                (1): Conv(\n",
       "                  (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): Identity()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (9): Upsample(scale_factor=2.0, mode='nearest')\n",
       "      (10): Concat()\n",
       "      (11): A2C2f(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0): C3k(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv3): Conv(\n",
       "              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (m): Sequential(\n",
       "              (0): Bottleneck(\n",
       "                (cv1): Conv(\n",
       "                  (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "                (cv2): Conv(\n",
       "                  (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "              )\n",
       "              (1): Bottleneck(\n",
       "                (cv1): Conv(\n",
       "                  (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "                (cv2): Conv(\n",
       "                  (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (12): Upsample(scale_factor=2.0, mode='nearest')\n",
       "      (13): Concat()\n",
       "      (14): A2C2f(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0): C3k(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv3): Conv(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (m): Sequential(\n",
       "              (0): Bottleneck(\n",
       "                (cv1): Conv(\n",
       "                  (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "                (cv2): Conv(\n",
       "                  (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "              )\n",
       "              (1): Bottleneck(\n",
       "                (cv1): Conv(\n",
       "                  (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "                (cv2): Conv(\n",
       "                  (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (15): Conv(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (16): Concat()\n",
       "      (17): A2C2f(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0): C3k(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv3): Conv(\n",
       "              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (m): Sequential(\n",
       "              (0): Bottleneck(\n",
       "                (cv1): Conv(\n",
       "                  (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "                (cv2): Conv(\n",
       "                  (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "              )\n",
       "              (1): Bottleneck(\n",
       "                (cv1): Conv(\n",
       "                  (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "                (cv2): Conv(\n",
       "                  (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (18): Conv(\n",
       "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (19): Concat()\n",
       "      (20): C3k2(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0): C3k(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv3): Conv(\n",
       "              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (m): Sequential(\n",
       "              (0): Bottleneck(\n",
       "                (cv1): Conv(\n",
       "                  (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "                (cv2): Conv(\n",
       "                  (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "              )\n",
       "              (1): Bottleneck(\n",
       "                (cv1): Conv(\n",
       "                  (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "                (cv2): Conv(\n",
       "                  (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (21): Detect(\n",
       "        (cv2): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1-2): 2 x Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): Conv2d(512, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (cv3): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): DWConv(\n",
       "                (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "                (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv(\n",
       "                (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (1): Sequential(\n",
       "              (0): DWConv(\n",
       "                (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "                (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv(\n",
       "                (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Conv2d(256, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1-2): 2 x Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): DWConv(\n",
       "                (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
       "                (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv(\n",
       "                (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (1): Sequential(\n",
       "              (0): DWConv(\n",
       "                (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "                (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv(\n",
       "                (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Conv2d(256, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (dfl): DFL(\n",
       "          (conv): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use GPU if available\n",
    "DEVICE = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Load the Anti-Alpine optimized model\n",
    "model = YOLO(\"weights/fine_tuned.pt\")\n",
    "model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Gap Calculation and Yolo video processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Dedining constants and variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Size and scale configuration\n",
    "FRAME_WIDTH = 1280  # Higher resolution for better detail\n",
    "CAR_LENGTH_METERS = 5.63  # Real car length in meters\n",
    "\n",
    "# FOR GAPS: use a lower global threshold to maximize detections\n",
    "GAP_DETECTION_THRESHOLD = 0.40  # Low threshold to detect all possible cars\n",
    "\n",
    "# Specific colors for each F1 team (BGR format for OpenCV)\n",
    "class_colors = {\n",
    "    'Ferrari': (0, 0, 255),         # Red (BGR)\n",
    "    'Mercedes': (200, 200, 200),    # Silver (BGR)\n",
    "    'Red Bull': (139, 0, 0),        # Dark Blue (BGR)\n",
    "    'McLaren': (0, 165, 255),       # Orange (BGR)\n",
    "    'Aston Martin': (0, 128, 0),    # Green (BGR)\n",
    "    'Alpine': (128, 0, 0),          # Blue (BGR)\n",
    "    'Williams': (205, 0, 0),        # Light Blue (BGR)\n",
    "    'Haas': (255, 255, 255),        # White (BGR)\n",
    "    'Kick Sauber': (255, 255, 0),   # Cyan (BGR)\n",
    "    'Racing Bulls': (0, 0, 255),    # Red (BGR)\n",
    "    'background': (128, 128, 128),  # Gray (BGR)\n",
    "    'unknown': (0, 255, 255)        # Yellow for cars without secure classification\n",
    "}\n",
    "\n",
    "# Thresholds to show classification (not for filtering detections)\n",
    "\n",
    "class_thresholds = {\n",
    "    'Kick Sauber': 0.55, \n",
    "    'Red Bull': 0.85,     \n",
    "    'Alpine': 0.85,       \n",
    "    'Ferrari': 0.45,       \n",
    "    'Haas': 0.40,          \n",
    "    'McLaren': 0.60,      \n",
    "    'Mercedes': 0.40,      \n",
    "    'Williams': 0.75,     \n",
    "    'background': 0.60    \n",
    "}\n",
    "\n",
    "# Detection history for stabilization\n",
    "last_detections = {}\n",
    "track_history = {}\n",
    "id_counter = 0\n",
    "class_history = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Calculating the gap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_gap(box1, box2, class1, class2):\n",
    "    \"\"\"Calculates the distance between centers using car width for scale\"\"\"\n",
    "    # Box centers\n",
    "    cx1, cy1 = (box1[0] + box1[2])/2, (box1[1] + box1[3])/2\n",
    "    cx2, cy2 = (box2[0] + box2[2])/2, (box2[1] + box2[3])/2\n",
    "    \n",
    "    # Distance in pixels\n",
    "    pixel_distance = np.hypot(cx2 - cx1, cy2 - cy1)\n",
    "    \n",
    "    # Scale based on average width of detected cars\n",
    "    avg_width = ((box1[2] - box1[0]) + (box2[2] - box2[0])) / 2\n",
    "    scale = CAR_LENGTH_METERS / avg_width if avg_width != 0 else 0\n",
    "    \n",
    "    # Calculate gap time at 300km/h (83.33 m/s)\n",
    "    speed_mps = 83.33  # Meters per second at 300km/h\n",
    "    gap_time = (pixel_distance * scale) / speed_mps\n",
    "    \n",
    "    return {\n",
    "        'distance': pixel_distance * scale,  # Distance in meters\n",
    "        'time': gap_time,                   # Time in seconds at 300km/h\n",
    "        'car1': class1,                     # Team of first car\n",
    "        'car2': class2                      # Team of second car\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Processing the video with YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_video_with_yolo(video_path, output_path=None):\n",
    "    global last_detections, track_history, id_counter, class_history, GAP_DETECTION_THRESHOLD, track_age\n",
    "    \n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error opening video: {video_path}\")\n",
    "        return\n",
    "    \n",
    "    # Get original video dimensions\n",
    "    original_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    original_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    current_frame = 0\n",
    "    \n",
    "    # Calculate new height maintaining aspect ratio\n",
    "    target_height = int(FRAME_WIDTH * original_height / original_width)\n",
    "    \n",
    "    out = None\n",
    "    if output_path:\n",
    "        # Change codec from 'mp4v' to 'XVID' which is more reliable\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "        out = cv2.VideoWriter(output_path, fourcc, fps, (FRAME_WIDTH, target_height))\n",
    "        if not out.isOpened():\n",
    "            print(f\"Error: Could not create output video file at {output_path}\")\n",
    "            print(\"Continuing without saving output...\")\n",
    "            output_path = None\n",
    "    \n",
    "    # Variables for calculating real FPS\n",
    "    frame_count = 0\n",
    "    start_time = pytime.time()\n",
    "    current_fps = 0\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret: \n",
    "            break\n",
    "        \n",
    "        frame_count += 1\n",
    "        current_frame += 1\n",
    "        \n",
    "        # Resize maintaining aspect ratio\n",
    "        frame_resized = cv2.resize(frame, (FRAME_WIDTH, target_height))\n",
    "        original_frame = frame_resized.copy()\n",
    "        \n",
    "        # Run YOLOv8 detection with optimized threshold for YOLOv12m fine-tuned model\n",
    "        results = model.predict(\n",
    "            source=frame_resized, \n",
    "            conf=GAP_DETECTION_THRESHOLD,  # Adjusted threshold (0.40 recommended)\n",
    "            iou=0.45,   # Standard IoU\n",
    "            max_det=20, # Maximum detections\n",
    "            verbose=False\n",
    "        )[0]\n",
    "        \n",
    "        # Current detections\n",
    "        current_detections = {}\n",
    "        \n",
    "        # Process detection results\n",
    "        if results.boxes and len(results.boxes) > 0:\n",
    "            boxes = results.boxes.xyxy.cpu().numpy()\n",
    "            confs = results.boxes.conf.cpu().numpy()\n",
    "            class_ids = results.boxes.cls.cpu().numpy().astype(int)\n",
    "            \n",
    "            # Create detection list with all information\n",
    "            detections = []\n",
    "            for i, box in enumerate(boxes):\n",
    "                x1, y1, x2, y2 = map(int, box)\n",
    "                conf = float(confs[i])\n",
    "                class_id = int(class_ids[i])\n",
    "                cls_name = model.names[class_id]\n",
    "                \n",
    "                # Determine whether to show team classification based on threshold\n",
    "                classified = conf >= class_thresholds.get(cls_name, 0.40)\n",
    "                \n",
    "                # Calculate center and size metrics\n",
    "                center_x = (x1 + x2) // 2\n",
    "                center_y = (y1 + y2) // 2\n",
    "                area = (x2 - x1) * (y2 - y1)\n",
    "                aspect_ratio = (x2 - x1) / (y2 - y1) if (y2 - y1) > 0 else 0\n",
    "                \n",
    "                # Filter by size/proportion for problematic classes\n",
    "                is_reasonable_size = area > (FRAME_WIDTH * target_height * 0.003)\n",
    "                is_reasonable_ratio = 0.4 < aspect_ratio < 2.5\n",
    "                \n",
    "                # Special filtering for Alpine and Red Bull\n",
    "                if (cls_name == 'Alpine' or cls_name == 'Red Bull'):\n",
    "                    if not (is_reasonable_size and is_reasonable_ratio and conf > class_thresholds.get(cls_name, 0.60)):\n",
    "                        classified = False\n",
    "                        cls_name = \"F1 Car\"  # Generic\n",
    "                \n",
    "                # Assign unique ID or retrieve existing ID\n",
    "                object_id = None\n",
    "                for old_id, old_info in last_detections.items():\n",
    "                    old_cx, old_cy = old_info['center']\n",
    "                    old_cls = old_info['class']\n",
    "                    \n",
    "                    # Distance between centers\n",
    "                    dist = np.sqrt((center_x - old_cx)**2 + (center_y - old_cy)**2)\n",
    "                    \n",
    "                    # If it's close, it could be the same object\n",
    "                    if dist < 100:\n",
    "                        object_id = old_id\n",
    "                        \n",
    "                        # If previous class was valid and new one is uncertain, keep the previous one\n",
    "                        if old_info['classified'] and not classified:\n",
    "                            cls_name = old_cls\n",
    "                            classified = True\n",
    "                        \n",
    "                        # Enhanced stabilization for problematic classes\n",
    "                        if classified and old_cls != cls_name:\n",
    "                            # Alpine has high mAP but low precision (0.447)\n",
    "                            if cls_name == 'Alpine' and conf < 0.65:\n",
    "                                if old_info['classified']:\n",
    "                                    cls_name = old_cls\n",
    "                            # McLaren has low precision (0.378)\n",
    "                            elif cls_name == 'McLaren' and conf < 0.55:\n",
    "                                if old_info['classified']:\n",
    "                                    cls_name = old_cls\n",
    "                            # Williams has good mAP50-95 (0.651) but classification problems\n",
    "                            elif cls_name == 'Williams':\n",
    "                                if old_info['classified'] and old_cls != 'Williams':\n",
    "                                    cls_name = old_cls\n",
    "                        break\n",
    "                \n",
    "                # If no match found, assign new ID\n",
    "                if object_id is None:\n",
    "                    object_id = id_counter\n",
    "                    id_counter += 1\n",
    "                    track_history[object_id] = []\n",
    "                    class_history[object_id] = []\n",
    "                    track_age[object_id] = 0\n",
    "                else:\n",
    "                    # Update track age for existing objects\n",
    "                    track_age[object_id] += 1\n",
    "                \n",
    "                # If track is new (first 3 frames), be more strict with Alpine/Red Bull\n",
    "                if track_age[object_id] < 3 and (cls_name == 'Alpine' or cls_name == 'Red Bull') and conf < 0.75:\n",
    "                    classified = False\n",
    "                    cls_name = \"F1 Car\"  # Use generic to avoid early false classifications\n",
    "                \n",
    "                # Update history\n",
    "                if object_id in class_history:\n",
    "                    # Only add to history if we're sure of the class\n",
    "                    if classified:\n",
    "                        class_history[object_id].append(cls_name)\n",
    "                        # Limit history to 5 classes\n",
    "                        if len(class_history[object_id]) > 5:\n",
    "                            class_history[object_id].pop(0)\n",
    "                    \n",
    "                    # Use the most common class from history for stability\n",
    "                    if len(class_history[object_id]) >= 5:  # Increased from 3 to 5\n",
    "                        counts = Counter(class_history[object_id])\n",
    "                        if counts:  # Make sure it's not empty\n",
    "                            most_common = counts.most_common(1)[0][0]\n",
    "                            cls_name = most_common\n",
    "                            classified = True\n",
    "                \n",
    "                # Save current detection\n",
    "                current_detections[object_id] = {\n",
    "                    'box': (x1, y1, x2, y2),\n",
    "                    'conf': conf,\n",
    "                    'class': cls_name,\n",
    "                    'classified': classified,\n",
    "                    'center': (center_x, center_y),\n",
    "                    'area': area,\n",
    "                    'y_bottom': y2  # For sorting by vertical position\n",
    "                }\n",
    "                \n",
    "                # Add to detection list for gap calculation\n",
    "                detections.append({\n",
    "                    'id': object_id,\n",
    "                    'box': (x1, y1, x2, y2),\n",
    "                    'class': cls_name,\n",
    "                    'classified': classified,\n",
    "                    'conf': conf,\n",
    "                    'y_bottom': y2\n",
    "                })\n",
    "            \n",
    "            # Sort by vertical position (cars more below first - closer)\n",
    "            detections = sorted(detections, key=lambda x: x['y_bottom'], reverse=True)\n",
    "            \n",
    "            # Eliminate ghost detections\n",
    "            detections_to_keep = []\n",
    "            for det in detections:\n",
    "                # If it's Alpine, verify if there are other cars very close (possible false positive)\n",
    "                if det['class'] == 'Alpine' and det['classified']:\n",
    "                    is_ghost = False\n",
    "                    \n",
    "                    for other in detections:\n",
    "                        if other['id'] != det['id']:\n",
    "                            # Calculate simple overlap between boxes\n",
    "                            x1a, y1a, x2a, y2a = det['box']\n",
    "                            x1b, y1b, x2b, y2b = other['box']\n",
    "                            \n",
    "                            overlap = max(0, min(x2a, x2b) - max(x1a, x1b)) * max(0, min(y2a, y2b) - max(y1a, y1b))\n",
    "                            area_a = (x2a - x1a) * (y2a - y1a)\n",
    "                            \n",
    "                            # If there's significant overlap, likely a false positive\n",
    "                            if overlap > 0.3 * area_a:\n",
    "                                is_ghost = True\n",
    "                                break\n",
    "                    \n",
    "                    if not is_ghost:\n",
    "                        detections_to_keep.append(det)\n",
    "                else:\n",
    "                    detections_to_keep.append(det)\n",
    "                    \n",
    "            detections = detections_to_keep\n",
    "            \n",
    "            # Draw boxes and gaps\n",
    "            for i, det in enumerate(detections):\n",
    "                x1, y1, x2, y2 = det['box']\n",
    "                cls_name = det['class']\n",
    "                conf = det['conf']\n",
    "                classified = det['classified']\n",
    "                \n",
    "                # Get specific color for the team\n",
    "                if classified:\n",
    "                    color = class_colors.get(cls_name, (0, 255, 0))\n",
    "                else:\n",
    "                    color = class_colors['unknown']  # Yellow for cars without secure classification\n",
    "                \n",
    "                # Draw box with team color\n",
    "                cv2.rectangle(frame_resized, (x1, y1), (x2, y2), color, 2)\n",
    "                \n",
    "                # Label with class and confidence\n",
    "                if classified:\n",
    "                    label = f\"{cls_name}: {conf:.2f}\"\n",
    "                else:\n",
    "                    label = f\"F1 Car: {conf:.2f}\"\n",
    "                \n",
    "                t_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)[0]\n",
    "                cv2.rectangle(frame_resized, (x1, y1-t_size[1]-3), (x1+t_size[0], y1), color, -1)\n",
    "                cv2.putText(frame_resized, label, (x1, y1-3), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "                \n",
    "                # Only if there's a next car\n",
    "                if i < len(detections)-1:\n",
    "                    next_det = detections[i+1]\n",
    "                    gap_info = calculate_gap(\n",
    "                        det['box'], next_det['box'], \n",
    "                        det['class'] if det['classified'] else \"F1 Car\", \n",
    "                        next_det['class'] if next_det['classified'] else \"F1 Car\"\n",
    "                    )\n",
    "                    \n",
    "                    # Connection points\n",
    "                    cx1, cy1 = int((x1+x2)/2), int(y1)  # Use top of the car\n",
    "                    nx1, ny1, nx2, ny2 = next_det['box']\n",
    "                    cx2, cy2 = int((nx1+nx2)/2), int(ny2)  # Use bottom of the next car\n",
    "                    \n",
    "                    # Diagonal line between cars\n",
    "                    cv2.line(frame_resized, (cx1, cy1), (cx2, cy2), (0, 255, 0), 2)\n",
    "                    \n",
    "                    # Text at midpoint with more information\n",
    "                    mid_x, mid_y = (cx1+cx2)//2, (cy1+cy2)//2\n",
    "                    \n",
    "                    # Distance and gap time\n",
    "                    dist_text = f\"{gap_info['distance']:.1f}m\"\n",
    "                    time_text = f\"{gap_info['time']:.2f}s\"\n",
    "                    \n",
    "                    # Background for text\n",
    "                    dist_size = cv2.getTextSize(dist_text, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)[0]\n",
    "                    time_size = cv2.getTextSize(time_text, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)[0]\n",
    "                    \n",
    "                    # Draw semi-transparent background\n",
    "                    overlay = frame_resized.copy()\n",
    "                    cv2.rectangle(overlay, \n",
    "                                 (mid_x - 5, mid_y - 50), \n",
    "                                 (mid_x + max(dist_size[0], time_size[0]) + 10, mid_y + 10),\n",
    "                                 (0, 0, 0), -1)\n",
    "                    cv2.addWeighted(overlay, 0.6, frame_resized, 0.4, 0, frame_resized)\n",
    "                    \n",
    "                    # Draw texts\n",
    "                    cv2.putText(frame_resized, dist_text, (mid_x, mid_y - 25),\n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "                    cv2.putText(frame_resized, time_text, (mid_x, mid_y),\n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "        \n",
    "        # Update last_detections for next iteration\n",
    "        last_detections = current_detections\n",
    "        \n",
    "        # Calculate FPS\n",
    "        if frame_count % 10 == 0:\n",
    "            current_time = pytime.time()\n",
    "            current_fps = 10.0 / (current_time - start_time)\n",
    "            start_time = current_time\n",
    "        \n",
    "        # Show FPS and model information\n",
    "        cv2.putText(frame_resized, f\"FPS: {current_fps:.1f}\", (20, 40),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "        \n",
    "        cv2.putText(frame_resized, \"F1 Gap Detection\", (FRAME_WIDTH - 300, 40),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "        \n",
    "        # Show detection mode and progress\n",
    "        detection_mode = f\"Detection Threshold: {GAP_DETECTION_THRESHOLD:.2f}\"\n",
    "        cv2.putText(frame_resized, detection_mode, (20, target_height - 30),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "        \n",
    "        # Show video progress\n",
    "        progress_text = f\"Frame: {current_frame}/{total_frames} ({current_frame/total_frames*100:.1f}%)\"\n",
    "        cv2.putText(frame_resized, progress_text, (FRAME_WIDTH - 400, target_height - 30),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "        \n",
    "        # Save processed frame if requested\n",
    "        if output_path:\n",
    "            out.write(frame_resized)\n",
    "        \n",
    "        # Show frame\n",
    "        cv2.imshow(\"F1 Gap Detection\", frame_resized)\n",
    "        key = cv2.waitKey(1)\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "        elif key == ord('+'):  # Increase threshold\n",
    "            GAP_DETECTION_THRESHOLD = min(GAP_DETECTION_THRESHOLD + 0.05, 0.95)\n",
    "            print(f\"Detection threshold increased to {GAP_DETECTION_THRESHOLD:.2f}\")\n",
    "        elif key == ord('-'):  # Decrease threshold\n",
    "            GAP_DETECTION_THRESHOLD = max(GAP_DETECTION_THRESHOLD - 0.05, 0.05)\n",
    "            print(f\"Detection threshold decreased to {GAP_DETECTION_THRESHOLD:.2f}\")\n",
    "        elif key == ord('d'):  # Skip forward 10 seconds\n",
    "            skip_frames = int(fps * 10)  # 10 seconds * fps = number of frames to skip\n",
    "            new_frame_pos = min(current_frame + skip_frames, total_frames - 1)\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, new_frame_pos)\n",
    "            current_frame = new_frame_pos - 1  # Will be incremented in the next cycle\n",
    "            # Temporarily reset tracking\n",
    "            last_detections = {}\n",
    "            print(f\"Skipped forward 10 seconds to frame {new_frame_pos}\")\n",
    "    \n",
    "    # Release resources\n",
    "    cap.release()\n",
    "    if output_path:\n",
    "        out.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Running a demo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error opening video: ../f1-strategy/data/videos/belgium_gp.f399.mp4\n"
     ]
    }
   ],
   "source": [
    "#Run with your video\n",
    "def main():\n",
    "    # video_path = \"../f1-strategy/data/videos/best_overtakes_2023.mp4.f399.mp4\"\n",
    "    # video_path = \"../f1-strategy/data/videos/spain_2023_race.mp4.f399.mp4\"\n",
    "    \n",
    "    video_path = \"../f1-strategy/data/videos/belgium_gp.f399.mp4\"\n",
    "    output_path = \"../f1-strategy/data/videos/gap_detection_output.mp4\"\n",
    "    process_video_with_yolo(video_path, output_path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Controls\n",
    "\n",
    "'q': out\n",
    "'+': more detection threshold\n",
    "'-': less detection threshold\n",
    "'d': 10 seconds ahead "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Gap Extraction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_gaps_from_video(video_path, sample_interval_seconds=10, output_csv=None, show_video=True):\n",
    "    \"\"\"\n",
    "    Process a video and extract gap data at regular intervals with visualization\n",
    "    \n",
    "    Args:\n",
    "        video_path: Path to the F1 video\n",
    "        sample_interval_seconds: How often to sample gap data (in seconds)\n",
    "        output_csv: Path to save CSV data (if None, will generate a default path)\n",
    "        show_video: Whether to display the video during processing\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with extracted gap data\n",
    "    \"\"\"\n",
    "    global last_detections, track_history, id_counter, class_history, GAP_DETECTION_THRESHOLD, track_age\n",
    "    \n",
    "    # Initialize empty list to store all gap data\n",
    "    all_gaps = []\n",
    "    \n",
    "    # Open video file\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error opening video: {video_path}\")\n",
    "        return None\n",
    "    \n",
    "    # Get video properties\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    # Calculate frame interval based on desired time interval\n",
    "    frame_interval = int(fps * sample_interval_seconds)\n",
    "    print(f\"Video FPS: {fps}, sampling every {frame_interval} frames ({sample_interval_seconds} seconds)\")\n",
    "    \n",
    "    # Initialize tracking variables\n",
    "    frame_count = 0\n",
    "    current_frame = 0\n",
    "    last_sample_frame = -frame_interval  # Ensure we get a sample on first frame\n",
    "    start_time = pytime.time()\n",
    "    current_fps = 0\n",
    "    \n",
    "    # Reset tracking variables\n",
    "    last_detections = {}\n",
    "    track_history = {}\n",
    "    id_counter = 0\n",
    "    class_history = {}\n",
    "    track_age = {}\n",
    "    \n",
    "    # Size configuration\n",
    "    original_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    original_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    target_height = int(FRAME_WIDTH * original_height / original_width)\n",
    "    \n",
    "    print(f\"Starting gap extraction from {video_path}...\")\n",
    "    print(f\"Will sample approximately every {sample_interval_seconds} seconds\")\n",
    "    \n",
    "    # Process video frames\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        frame_count += 1\n",
    "        current_frame += 1\n",
    "        \n",
    "        # Calculate video timestamp in seconds\n",
    "        timestamp = current_frame / fps\n",
    "        \n",
    "        # Determine if this is a sample frame\n",
    "        is_sample_frame = (current_frame - last_sample_frame >= frame_interval)\n",
    "        \n",
    "        # Skip processing if not showing video and not a sample frame\n",
    "        if not show_video and not is_sample_frame:\n",
    "            if current_frame % 100 == 0:  # Show progress occasionally\n",
    "                print(f\"Progress: Frame {current_frame}/{total_frames} ({current_frame/total_frames*100:.1f}%)\")\n",
    "            continue\n",
    "        \n",
    "        # Mark this as a sample frame if needed\n",
    "        if is_sample_frame:\n",
    "            last_sample_frame = current_frame\n",
    "            print(f\"Taking sample at frame {current_frame} (timestamp: {timestamp:.2f}s)\")\n",
    "        \n",
    "        # Resize frame for processing\n",
    "        frame_resized = cv2.resize(frame, (FRAME_WIDTH, target_height))\n",
    "        original_frame = frame_resized.copy()\n",
    "        \n",
    "        # Run YOLOv8 detection with optimized threshold\n",
    "        results = model.predict(\n",
    "            source=frame_resized, \n",
    "            conf=GAP_DETECTION_THRESHOLD,  # Using updated threshold (0.40 recommended)\n",
    "            iou=0.45,\n",
    "            max_det=20,\n",
    "            verbose=False\n",
    "        )[0]\n",
    "        \n",
    "        # Current detections dictionary\n",
    "        current_detections = {}\n",
    "        \n",
    "        # Process detection results\n",
    "        if results.boxes and len(results.boxes) > 0:\n",
    "            boxes = results.boxes.xyxy.cpu().numpy()\n",
    "            confs = results.boxes.conf.cpu().numpy()\n",
    "            class_ids = results.boxes.cls.cpu().numpy().astype(int)\n",
    "            \n",
    "            # Create detection list\n",
    "            detections = []\n",
    "            \n",
    "            # Process each detected object\n",
    "            for i, box in enumerate(boxes):\n",
    "                x1, y1, x2, y2 = map(int, box)\n",
    "                conf = float(confs[i])\n",
    "                class_id = int(class_ids[i])\n",
    "                cls_name = model.names[class_id]\n",
    "                \n",
    "                # Check if confidence meets threshold\n",
    "                classified = conf >= class_thresholds.get(cls_name, 0.40)\n",
    "                \n",
    "                # Calculate size metrics for filtering\n",
    "                center_x = (x1 + x2) // 2\n",
    "                center_y = (y1 + y2) // 2\n",
    "                area = (x2 - x1) * (y2 - y1)\n",
    "                aspect_ratio = (x2 - x1) / (y2 - y1) if (y2 - y1) > 0 else 0\n",
    "                \n",
    "                # Filter by size/proportion for problematic classes\n",
    "                is_reasonable_size = area > (FRAME_WIDTH * target_height * 0.003)\n",
    "                is_reasonable_ratio = 0.4 < aspect_ratio < 2.5\n",
    "                \n",
    "                # Special filtering for Alpine and Red Bull\n",
    "                if (cls_name == 'Alpine' or cls_name == 'Red Bull'):\n",
    "                    if not (is_reasonable_size and is_reasonable_ratio and conf > class_thresholds.get(cls_name, 0.60)):\n",
    "                        classified = False\n",
    "                        cls_name = \"F1 Car\"  # Generic classification\n",
    "                \n",
    "                # Try to match with existing objects for tracking\n",
    "                object_id = None\n",
    "                for old_id, old_info in last_detections.items():\n",
    "                    old_cx, old_cy = old_info['center']\n",
    "                    old_cls = old_info['class']\n",
    "                    \n",
    "                    # Calculate distance between centers\n",
    "                    dist = np.sqrt((center_x - old_cx)**2 + (center_y - old_cy)**2)\n",
    "                    \n",
    "                    # If close enough, it's likely the same car\n",
    "                    if dist < 100:\n",
    "                        object_id = old_id\n",
    "                        \n",
    "                        # Use previous classification if it was better\n",
    "                        if old_info['classified'] and not classified:\n",
    "                            cls_name = old_cls\n",
    "                            classified = True\n",
    "                        \n",
    "                        # Enhanced stabilization for problematic classes\n",
    "                        if classified and old_cls != cls_name:\n",
    "                            # Alpine has high mAP but low precision (0.447)\n",
    "                            if cls_name == 'Alpine' and conf < 0.65:\n",
    "                                if old_info['classified']:\n",
    "                                    cls_name = old_cls\n",
    "                            # McLaren has low precision (0.378)\n",
    "                            elif cls_name == 'McLaren' and conf < 0.55:\n",
    "                                if old_info['classified']:\n",
    "                                    cls_name = old_cls\n",
    "                            # Williams filtering\n",
    "                            elif cls_name == 'Williams':\n",
    "                                if old_info['classified'] and old_cls != 'Williams':\n",
    "                                    cls_name = old_cls\n",
    "                        break\n",
    "                \n",
    "                # If no match found, create new ID\n",
    "                if object_id is None:\n",
    "                    object_id = id_counter\n",
    "                    id_counter += 1\n",
    "                    track_history[object_id] = []\n",
    "                    class_history[object_id] = []\n",
    "                    track_age[object_id] = 0\n",
    "                else:\n",
    "                    # Update track age for existing objects\n",
    "                    track_age[object_id] += 1\n",
    "                \n",
    "                # If track is new, be more strict with problematic classes\n",
    "                if track_age[object_id] < 3 and (cls_name == 'Alpine' or cls_name == 'Red Bull') and conf < 0.75:\n",
    "                    classified = False\n",
    "                    cls_name = \"F1 Car\"  # Use generic for early frames\n",
    "                \n",
    "                # Update classification history for stability\n",
    "                if object_id in class_history:\n",
    "                    if classified:\n",
    "                        class_history[object_id].append(cls_name)\n",
    "                        # Keep history limited\n",
    "                        if len(class_history[object_id]) > 5:\n",
    "                            class_history[object_id].pop(0)\n",
    "                    \n",
    "                    # Use most common class from history - increased from 3 to 5 for better stability\n",
    "                    if len(class_history[object_id]) >= 5:\n",
    "                        counts = Counter(class_history[object_id])\n",
    "                        if counts:\n",
    "                            most_common = counts.most_common(1)[0][0]\n",
    "                            cls_name = most_common\n",
    "                            classified = True\n",
    "                \n",
    "                # Save current detection\n",
    "                current_detections[object_id] = {\n",
    "                    'box': (x1, y1, x2, y2),\n",
    "                    'conf': conf,\n",
    "                    'class': cls_name,\n",
    "                    'classified': classified,\n",
    "                    'center': (center_x, center_y),\n",
    "                    'area': area,\n",
    "                    'y_bottom': y2\n",
    "                }\n",
    "                \n",
    "                # Add to detection list\n",
    "                detections.append({\n",
    "                    'id': object_id,\n",
    "                    'box': (x1, y1, x2, y2),\n",
    "                    'class': cls_name,\n",
    "                    'classified': classified,\n",
    "                    'conf': conf,\n",
    "                    'y_bottom': y2\n",
    "                })\n",
    "            \n",
    "            # Sort by vertical position (cars more below first - closer to camera)\n",
    "            detections = sorted(detections, key=lambda x: x['y_bottom'], reverse=True)\n",
    "            \n",
    "            # Eliminate ghost detections\n",
    "            detections_to_keep = []\n",
    "            for det in detections:\n",
    "                # If it's Alpine, verify if there are other cars very close (possible false positive)\n",
    "                if det['class'] == 'Alpine' and det['classified']:\n",
    "                    is_ghost = False\n",
    "                    \n",
    "                    for other in detections:\n",
    "                        if other['id'] != det['id']:\n",
    "                            # Calculate simple overlap between boxes\n",
    "                            x1a, y1a, x2a, y2a = det['box']\n",
    "                            x1b, y1b, x2b, y2b = other['box']\n",
    "                            \n",
    "                            overlap = max(0, min(x2a, x2b) - max(x1a, x1b)) * max(0, min(y2a, y2b) - max(y1a, y1b))\n",
    "                            area_a = (x2a - x1a) * (y2a - y1a)\n",
    "                            \n",
    "                            # If there's significant overlap, likely a false positive\n",
    "                            if overlap > 0.3 * area_a:\n",
    "                                is_ghost = True\n",
    "                                break\n",
    "                    \n",
    "                    if not is_ghost:\n",
    "                        detections_to_keep.append(det)\n",
    "                else:\n",
    "                    detections_to_keep.append(det)\n",
    "                    \n",
    "            detections = detections_to_keep\n",
    "            \n",
    "            # Calculate gaps between consecutive cars\n",
    "            frame_gaps = []\n",
    "            \n",
    "            # Process detections for visualization\n",
    "            if show_video:\n",
    "                for i, det in enumerate(detections):\n",
    "                    x1, y1, x2, y2 = det['box']\n",
    "                    cls_name = det['class']\n",
    "                    conf = det['conf']\n",
    "                    classified = det['classified']\n",
    "                    \n",
    "                    # Get specific color for the team\n",
    "                    if classified:\n",
    "                        color = class_colors.get(cls_name, (0, 255, 0))\n",
    "                    else:\n",
    "                        color = class_colors['unknown']  # Yellow for cars without secure classification\n",
    "                    \n",
    "                    # Draw box with team color\n",
    "                    cv2.rectangle(frame_resized, (x1, y1), (x2, y2), color, 2)\n",
    "                    \n",
    "                    # Label with class and confidence\n",
    "                    if classified:\n",
    "                        label = f\"{cls_name}: {conf:.2f}\"\n",
    "                    else:\n",
    "                        label = f\"F1 Car: {conf:.2f}\"\n",
    "                    \n",
    "                    t_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)[0]\n",
    "                    cv2.rectangle(frame_resized, (x1, y1-t_size[1]-3), (x1+t_size[0], y1), color, -1)\n",
    "                    cv2.putText(frame_resized, label, (x1, y1-3), \n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "                    \n",
    "                    # Only if there's a next car\n",
    "                    if i < len(detections)-1:\n",
    "                        next_det = detections[i+1]\n",
    "                        gap_info = calculate_gap(\n",
    "                            det['box'], next_det['box'], \n",
    "                            det['class'] if det['classified'] else \"F1 Car\", \n",
    "                            next_det['class'] if next_det['classified'] else \"F1 Car\"\n",
    "                        )\n",
    "                        \n",
    "                        # Save gap info for data collection if this is a sample frame\n",
    "                        if is_sample_frame:\n",
    "                            frame_gaps.append({\n",
    "                                'frame': current_frame,\n",
    "                                'timestamp': timestamp,\n",
    "                                'car1_id': det['id'],\n",
    "                                'car2_id': next_det['id'],\n",
    "                                'car1_team': gap_info['car1'],\n",
    "                                'car2_team': gap_info['car2'],\n",
    "                                'distance_meters': gap_info['distance'],\n",
    "                                'gap_seconds': gap_info['time']\n",
    "                            })\n",
    "                        \n",
    "                        # Connection points\n",
    "                        cx1, cy1 = int((x1+x2)/2), int(y1)  # Use top of the car\n",
    "                        nx1, ny1, nx2, ny2 = next_det['box']\n",
    "                        cx2, cy2 = int((nx1+nx2)/2), int(ny2)  # Use bottom of the next car\n",
    "                        \n",
    "                        # Diagonal line between cars\n",
    "                        line_color = (0, 0, 255) if is_sample_frame else (0, 255, 0)  # Red if sampled, otherwise green\n",
    "                        line_thickness = 3 if is_sample_frame else 2  # Thicker if sampled\n",
    "                        cv2.line(frame_resized, (cx1, cy1), (cx2, cy2), line_color, line_thickness)\n",
    "                        \n",
    "                        # Text at midpoint with more information\n",
    "                        mid_x, mid_y = (cx1+cx2)//2, (cy1+cy2)//2\n",
    "                        \n",
    "                        # Distance and gap time\n",
    "                        dist_text = f\"{gap_info['distance']:.1f}m\"\n",
    "                        time_text = f\"{gap_info['time']:.2f}s\"\n",
    "                        \n",
    "                        # Background for text\n",
    "                        dist_size = cv2.getTextSize(dist_text, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)[0]\n",
    "                        time_size = cv2.getTextSize(time_text, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)[0]\n",
    "                        \n",
    "                        # Draw semi-transparent background\n",
    "                        overlay = frame_resized.copy()\n",
    "                        bg_color = (0, 0, 180) if is_sample_frame else (0, 0, 0)  # Dark red if sampled\n",
    "                        cv2.rectangle(overlay, \n",
    "                                    (mid_x - 5, mid_y - 50), \n",
    "                                    (mid_x + max(dist_size[0], time_size[0]) + 10, mid_y + 10),\n",
    "                                    bg_color, -1)\n",
    "                        cv2.addWeighted(overlay, 0.6, frame_resized, 0.4, 0, frame_resized)\n",
    "                        \n",
    "                        # Draw texts - add \"SAVED\" mark if sampled\n",
    "                        if is_sample_frame:\n",
    "                            saved_text = \"SAVED\"\n",
    "                            cv2.putText(frame_resized, saved_text, (mid_x, mid_y - 50),\n",
    "                                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "                        \n",
    "                        # Draw gap measurements\n",
    "                        cv2.putText(frame_resized, dist_text, (mid_x, mid_y - 25),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "                        cv2.putText(frame_resized, time_text, (mid_x, mid_y),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "            \n",
    "            # If processing a sample frame, also collect gap data without visualization\n",
    "            elif is_sample_frame:\n",
    "                for i, det in enumerate(detections):\n",
    "                    if i < len(detections)-1:\n",
    "                        next_det = detections[i+1]\n",
    "                        gap_info = calculate_gap(\n",
    "                            det['box'], next_det['box'], \n",
    "                            det['class'] if det['classified'] else \"F1 Car\", \n",
    "                            next_det['class'] if next_det['classified'] else \"F1 Car\"\n",
    "                        )\n",
    "                        \n",
    "                        frame_gaps.append({\n",
    "                            'frame': current_frame,\n",
    "                            'timestamp': round(timestamp, 2),\n",
    "                            'car1_id': det['id'],\n",
    "                            'car2_id': next_det['id'],\n",
    "                            'car1_team': gap_info['car1'],\n",
    "                            'car2_team': gap_info['car2'],\n",
    "                            'distance_meters': round(gap_info['distance'], 2),\n",
    "                            'gap_seconds': round(gap_info['time'], 2)\n",
    "                        })\n",
    "            \n",
    "            # Add all gaps from this frame to our collection if it's a sample frame\n",
    "            if is_sample_frame:\n",
    "                all_gaps.extend(frame_gaps)\n",
    "                print(f\"Found {len(frame_gaps)} car gaps at timestamp {timestamp:.2f}s\")\n",
    "        \n",
    "        # Update last_detections for next iteration\n",
    "        last_detections = current_detections\n",
    "        \n",
    "        # Calculate FPS for display\n",
    "        if show_video and frame_count % 10 == 0:\n",
    "            current_time = pytime.time()\n",
    "            current_fps = 10.0 / (current_time - start_time)\n",
    "            start_time = current_time\n",
    "        \n",
    "        # Show visual elements if requested\n",
    "        if show_video:\n",
    "            # Show FPS and model information\n",
    "            cv2.putText(frame_resized, f\"FPS: {current_fps:.1f}\", (20, 40),\n",
    "                      cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "            \n",
    "            # Add \"SAMPLE FRAME\" indicator if this is a frame being saved\n",
    "            if is_sample_frame:\n",
    "                cv2.putText(frame_resized, \" SAMPLE FRAME\", (FRAME_WIDTH - 300, 40),\n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "            else:\n",
    "                cv2.putText(frame_resized, \"F1 Gap Extraction\", (FRAME_WIDTH - 300, 40),\n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "            \n",
    "            # Show detection threshold\n",
    "            detection_mode = f\"Detection Threshold: {GAP_DETECTION_THRESHOLD:.2f}\"\n",
    "            cv2.putText(frame_resized, detection_mode, (20, target_height - 30),\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "            \n",
    "            # Show progress\n",
    "            progress_text = f\"Frame: {current_frame}/{total_frames} ({current_frame/total_frames*100:.1f}%)\"\n",
    "            cv2.putText(frame_resized, progress_text, (FRAME_WIDTH - 400, target_height - 30),\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "            \n",
    "            # Show the frame\n",
    "            cv2.imshow(\"F1 Gap Extraction\", frame_resized)\n",
    "            \n",
    "            # Handle key presses\n",
    "            key = cv2.waitKey(1)\n",
    "            if key == ord('q'):\n",
    "                break\n",
    "            elif key == ord('+'):  # Increase threshold\n",
    "                GAP_DETECTION_THRESHOLD = min(GAP_DETECTION_THRESHOLD + 0.05, 0.95)\n",
    "                print(f\"Detection threshold increased to {GAP_DETECTION_THRESHOLD:.2f}\")\n",
    "            elif key == ord('-'):  # Decrease threshold\n",
    "                GAP_DETECTION_THRESHOLD = max(GAP_DETECTION_THRESHOLD - 0.05, 0.05)\n",
    "                print(f\"Detection threshold decreased to {GAP_DETECTION_THRESHOLD:.2f}\")\n",
    "            elif key == ord('d'):  # Skip forward 10 seconds\n",
    "                skip_frames = int(fps * 10)\n",
    "                new_frame_pos = min(current_frame + skip_frames, total_frames - 1)\n",
    "                cap.set(cv2.CAP_PROP_POS_FRAMES, new_frame_pos)\n",
    "                current_frame = new_frame_pos - 1\n",
    "                last_detections = {}\n",
    "                print(f\"Skipped forward 10 seconds to frame {new_frame_pos}\")\n",
    "    \n",
    "    # Release video resource\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    if all_gaps:\n",
    "        gaps_df = pd.DataFrame(all_gaps)\n",
    "        \n",
    "        # Save to CSV if requested\n",
    "        if output_csv is None:\n",
    "            # Generate default filename based on video name\n",
    "            video_name = os.path.basename(video_path).split('.')[0]\n",
    "            timestamp_str = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            output_csv = f\"../f1-strategy/data/gaps/gap_data_{video_name}_{timestamp_str}.csv\"\n",
    "        \n",
    "        # Create directory if it doesn't exist\n",
    "        os.makedirs(os.path.dirname(output_csv), exist_ok=True)\n",
    "        \n",
    "        # Save data\n",
    "        gaps_df.to_csv(output_csv, index=False, float_format='%.3f')\n",
    "        print(f\"Gap data saved to {output_csv}\")\n",
    "        print(f\"Total of {len(gaps_df)} gap measurements collected\")\n",
    "        \n",
    "        return gaps_df\n",
    "    else:\n",
    "        print(\"No gap data could be collected!\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Run gap extraction with visualization\n",
    "def main_extract_gaps():\n",
    "    \"\"\"Extract gaps from the video at 10-second intervals and save to CSV\"\"\"\n",
    "    video_path = \"videos/belgium_gp.f399.mp4\"\n",
    "    \n",
    "    # Run extraction with default 10-second interval, showing video\n",
    "    gap_data = extract_gaps_from_video(\n",
    "        video_path,\n",
    "        sample_interval_seconds=10,\n",
    "        show_video=True  # Enable video display\n",
    "    )\n",
    "    \n",
    "    # Display sample of extracted data\n",
    "    if gap_data is not None and not gap_data.empty:\n",
    "        print(\"\\nSample gap data:\")\n",
    "        print(gap_data.head())\n",
    "        \n",
    "        # Show some basic statistics\n",
    "        print(\"\\nGap statistics (seconds):\")\n",
    "        print(gap_data['gap_seconds'].describe())\n",
    "    \n",
    "    return gap_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video FPS: 50, sampling every 500 frames (10 seconds)\n",
      "Starting gap extraction from videos/belgium_gp.f399.mp4...\n",
      "Will sample approximately every 10 seconds\n",
      "Taking sample at frame 1 (timestamp: 0.02s)\n",
      "Found 1 car gaps at timestamp 0.02s\n",
      "Skipped forward 10 seconds to frame 529\n",
      "Taking sample at frame 529 (timestamp: 10.58s)\n",
      "Found 0 car gaps at timestamp 10.58s\n",
      "Skipped forward 10 seconds to frame 1038\n",
      "Taking sample at frame 1038 (timestamp: 20.76s)\n",
      "Found 2 car gaps at timestamp 20.76s\n",
      "Skipped forward 10 seconds to frame 1627\n",
      "Taking sample at frame 1627 (timestamp: 32.54s)\n",
      "Found 0 car gaps at timestamp 32.54s\n",
      "Skipped forward 10 seconds to frame 2162\n",
      "Taking sample at frame 2162 (timestamp: 43.24s)\n",
      "Skipped forward 10 seconds to frame 2901\n",
      "Taking sample at frame 2901 (timestamp: 58.02s)\n",
      "Found 0 car gaps at timestamp 58.02s\n",
      "Detection threshold decreased to 0.35\n",
      "Detection threshold decreased to 0.30\n",
      "Skipped forward 10 seconds to frame 3464\n",
      "Taking sample at frame 3464 (timestamp: 69.28s)\n",
      "Found 4 car gaps at timestamp 69.28s\n",
      "Skipped forward 10 seconds to frame 4067\n",
      "Taking sample at frame 4067 (timestamp: 81.34s)\n",
      "Detection threshold increased to 0.35\n",
      "Skipped forward 10 seconds to frame 4698\n",
      "Taking sample at frame 4698 (timestamp: 93.96s)\n",
      "Found 2 car gaps at timestamp 93.96s\n",
      "Skipped forward 10 seconds to frame 5416\n",
      "Taking sample at frame 5416 (timestamp: 108.32s)\n",
      "Found 0 car gaps at timestamp 108.32s\n",
      "Taking sample at frame 5916 (timestamp: 118.32s)\n",
      "Gap data saved to ../f1-strategy/data/gaps/gap_data_belgium_gp_20250517_182329.csv\n",
      "Total of 9 gap measurements collected\n",
      "\n",
      "Sample gap data:\n",
      "   frame  timestamp  car1_id  car2_id car1_team car2_team  distance_meters  \\\n",
      "0      1       0.02        1        0    F1 Car    F1 Car        13.594381   \n",
      "1   1038      20.76        7        8   Mclaren   Ferarri         4.300427   \n",
      "2   1038      20.76        8        9   Ferarri    F1 Car         3.100436   \n",
      "3   3464      69.28       51       52   Ferarri  Mercedes         4.650316   \n",
      "4   3464      69.28       52       53  Mercedes    F1 Car        13.114265   \n",
      "\n",
      "   gap_seconds  \n",
      "0     0.163139  \n",
      "1     0.051607  \n",
      "2     0.037207  \n",
      "3     0.055806  \n",
      "4     0.157377  \n",
      "\n",
      "Gap statistics (seconds):\n",
      "count    9.000000\n",
      "mean     0.089516\n",
      "std      0.062013\n",
      "min      0.019567\n",
      "25%      0.051607\n",
      "50%      0.062960\n",
      "75%      0.157377\n",
      "max      0.186934\n",
      "Name: gap_seconds, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# # Cell 4: Execute the extraction\n",
    "if __name__ == \"__main__\":\n",
    "     gap_data = main_extract_gaps()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Conclussions\n",
    "\n",
    "In this notebook, we've successfully implemented a computer vision system that:\n",
    "\n",
    "1. Detects F1 cars in video footage using our YOLOv8 model\n",
    "2. Calculates gaps between consecutive cars in both meters and seconds\n",
    "3. Extracts data at regular intervals (every 10 seconds) to feed into our strategy system\n",
    "4. Saves this information to structured CSV files with team identification\n",
    "\n",
    "\n",
    "### 3.1 CSV Structure\n",
    "\n",
    "Our gap extraction system produces CSV files with the following columns:\n",
    "\n",
    "- ``frame``: Frame number in the video\n",
    "- ``timestamp``: Time in seconds from the start of the video\n",
    "- ``car1_id and car2_id``: Unique identifiers for each detected car\n",
    "- ``car1_team and car2_team``: Team identifications based on our model\n",
    "- ``distance_meters``: Physical distance between cars in meters\n",
    "- ``gap_seconds``: Time gap between cars (in seconds at 300 km/h)\n",
    "\n",
    "This data provides the foundation for our gap-based strategy rules, enabling our expert system to make informed decisions about:\n",
    "\n",
    "- Undercut/overcut opportunities\n",
    "- Traffic management\n",
    "- Defensive positioning\n",
    "\n",
    "\n",
    "### 3.2 Next Steps\n",
    "With our gap data now available, the next phase is to integrate this information into our expert system by:\n",
    "\n",
    "- Creating gap-specific rules that detect strategic opportunities\n",
    "- Combining gap data with our existing tire degradation and lap time models\n",
    "- Implementing undercut/overcut detection logic based on real-world F1 strategy principles\n",
    "\n",
    "In the next notebook (``N05_gap_strategy_rules.ipynb``), we'll develop these rules and integrate all components of our F1 strategy system.\n",
    "\n",
    "However, due to that this data can be not enough or too much erratic, we will do the gap rules with fastf1 data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
